{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data into dataframes (datasets)\n",
    "# ignore this if you can't execute the sql and simple use the next cell to load the data\n",
    "\n",
    "from sqlalchemy import create_engine\n",
    "import pymysql\n",
    "import pandas as pd\n",
    "\n",
    "db_connection_str = 'mysql+pymysql://root:london12@localhost/BrexChallenge'\n",
    "db_connection = create_engine(db_connection_str)\n",
    "\n",
    "df_customer = pd.read_sql(\"\"\" SELECT id as customer_id FROM tblCustomerAccounts \"\"\", con=db_connection)\n",
    "df_accounts = pd.read_sql(\"\"\" SELECT id as account_id, customer_account_id FROM tblFinancialsAccounts \"\"\", con=db_connection)\n",
    "df_balance = pd.read_sql(\"\"\" SELECT * FROM tblFinancialsBalancesGroupedByDate ORDER BY account_id, accrual_date_bal \"\"\", con=db_connection)\n",
    "df_transaction = pd.read_sql(\"\"\" SELECT * FROM tblFinancialsTransactionsGroupedByDate ORDER BY account_id, accrual_date_tran \"\"\", con=db_connection)\n",
    "df_date = pd.read_sql(\"\"\" SELECT date FROM tblDates ORDER BY date \"\"\", con=db_connection)\n",
    "\n",
    "print(df_customer)\n",
    "print(df_accounts)\n",
    "print(df_balance)\n",
    "print(df_transaction)\n",
    "print(df_date)\n",
    "\n",
    "df_customer.to_csv('df_datafiles/df_customer.csv', sep=',', encoding='utf-8', index=False)\n",
    "df_accounts.to_csv('df_datafiles/df_accounts.csv', sep=',', encoding='utf-8', index=False)\n",
    "df_balance.to_csv('df_datafiles/df_balance.csv', sep=',', encoding='utf-8', index=False)\n",
    "df_transaction.to_csv('df_datafiles/df_transaction.csv', sep=',', encoding='utf-8', index=False)\n",
    "df_date.to_csv('df_datafiles/df_date.csv', sep=',', encoding='utf-8', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_customer = pd.read_csv('df_datafiles/df_customer.csv')\n",
    "df_accounts = pd.read_csv('df_datafiles/df_accounts.csv')\n",
    "df_balance = pd.read_csv('df_datafiles/df_balance.csv')\n",
    "df_transaction = pd.read_csv('df_datafiles/df_transaction.csv')\n",
    "df_date = pd.read_csv('df_datafiles/df_date.csv')\n",
    "\n",
    "print(df_customer)\n",
    "print(df_accounts)\n",
    "print(df_balance)\n",
    "print(df_transaction)\n",
    "print(df_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# join the customer & accounts table (we need the balance per customer, not account)\n",
    "\n",
    "df_customer_and_account = pd.merge(df_customer, df_accounts,  how='left', left_on=['customer_id'], right_on = ['customer_account_id'])\n",
    "df_customer_and_account.sort_values(by=['customer_id', 'customer_account_id'], inplace=True)\n",
    "df_customer_and_account = df_customer_and_account[['customer_id', 'account_id']]\n",
    "\n",
    "print(df_customer_and_account)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a cross-join between the date and account datasets\n",
    "\n",
    "def cartesian_product_basic(left, right):\n",
    "    return (\n",
    "       left.assign(key=1).merge(right.assign(key=1), on='key').drop('key', 1))\n",
    "\n",
    "df_dates_accounts = cartesian_product_basic(df_date, df_customer_and_account)\n",
    "df_dates_accounts.sort_values(by=['customer_id','account_id', 'date'], inplace=True)\n",
    "print(df_dates_accounts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge/join/add balances to df_dates_accounts dataset\n",
    "\n",
    "df_merged = pd.merge(df_dates_accounts, df_balance[['account_id', 'accrual_date_bal', 'amount_bal']],  how='left', left_on=['date', 'account_id'], right_on = ['accrual_date_bal', 'account_id'])\n",
    "df_merged.sort_values(by=['customer_id', 'account_id','date'], inplace=True)\n",
    "print(df_merged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge/join/add transactions to accounts_dates dataset\n",
    "\n",
    "df_merged = pd.merge(df_merged, df_transaction[['account_id', 'accrual_date_tran', 'amount_tran']],  how='left', left_on=['date', 'account_id'], right_on = ['accrual_date_tran', 'account_id'])\n",
    "df_merged.sort_values(by=['customer_id', 'account_id','date'], inplace=True)\n",
    "print(df_merged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# declutter - remove any fields that are not currently required\n",
    "\n",
    "df_merged = df_merged[['customer_id', 'account_id', 'date', 'amount_bal', 'amount_tran']]\n",
    "print(df_merged)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# group the balance and transactions at the date and customer level (no need to have multiple transactions and balances per day)\n",
    "# this dataset will then be merged with the all-dates/customer_id table later\n",
    "\n",
    "# split out the columns of the dataframe into series then groupby and sum - had to seperate out as I'm not sure it's possibe to group then sum whilst ignoring NA (skipna=false) with a single line of code\n",
    "# this is important as when I dont want the sums to = 0 when they are NAN as later want to do ffill and take the previous value (and not assume NAN=0)\n",
    "df_balance = df_merged[['customer_id', 'account_id', 'date', 'amount_bal']]\n",
    "df_transaction = df_merged[['customer_id', 'account_id', 'date', 'amount_tran']]\n",
    "\n",
    "# this is correct for production (after you remove the where clause(filter)) - but I'm filtering further below on account_id instad so I can recon with jo's example\n",
    "df_balance = (df_balance[df_balance['customer_id'] == 'cuacc_clitbxcx303bg1vlkky084lt'].groupby(['customer_id', 'date'], as_index=False).agg({'amount_bal': lambda x: x.sum(min_count=1, skipna=False)}))\n",
    "df_transaction = (df_transaction[df_transaction['customer_id'] == 'cuacc_clitbxcx303bg1vlkky084lt'].groupby(['customer_id', 'date'], as_index=False).agg({'amount_tran': lambda x: x.sum(min_count=1, skipna=False)}))\n",
    "df_merged = (df_balance.merge(df_transaction, left_on=['customer_id', 'date'], right_on=['customer_id', 'date']))\n",
    "\n",
    "print(df_merged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new dataset where we have just the balances and dates \n",
    "# (this will be used to compute the opening balance later)\n",
    "\n",
    "dfBalanceExcludingNaN = df_balance[df_balance.amount_bal.notnull()]\n",
    "print(dfBalanceExcludingNaN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we want to create a dataset that has the correct shape/schema of the final dataset (currently df_merged)\n",
    "# we want to add the date of the next balance to the first record so that we can compute the opening balance:\n",
    "# to do this we need the first balance and date\n",
    "# we use the date to then sum the transactions between the opening balance date and first balance date (#todo)\n",
    "\n",
    "left = pd.DataFrame(df_merged)\n",
    "right = (dfBalanceExcludingNaN[dfBalanceExcludingNaN['customer_id'] == 'cuacc_clitbxcx303bg1vlkky084lt'].groupby(['customer_id', 'date'], as_index=False).agg({'amount_bal': lambda x: x.sum(min_count=1, skipna=False)}))\n",
    "\n",
    "left['date'] = pd.to_datetime(left['date'])\n",
    "right['date'] = pd.to_datetime(right['date'])\n",
    "#left.set_index('date', inplace=True)\n",
    "#right.set_index('date', inplace=True)\n",
    "\n",
    "##print(left)\n",
    "##print(right)\n",
    "## pd.merge_asof(left, right, on='a', direction='forward')\n",
    "\n",
    "##print(pd.merge_asof(left, right, left_index=True, right_index=True))\n",
    "\n",
    "df_merged01 = (pd.merge_asof(left, right, left_index=True, right_index=True, direction='forward'))\n",
    "print(df_merged01)\n",
    "df_merged01.to_csv('_brex_021.csv', sep=',', encoding='utf-8')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
